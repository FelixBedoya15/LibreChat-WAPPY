# ‚ö†Ô∏è DOCUMENTO CR√çTICO - Lo Que NO Se Debe Cambiar

## ‚ùå Cambios Que ROMPEN La Funcionalidad

### 1. **responseModalities**
```javascript
// ‚ùå NUNCA CAMBIAR ESTO:
responseModalities: ['AUDIO']

// ‚ùå SI AGREGAS TEXT, LA IA DEJA DE RESPONDER COMPLETAMENTE:
responseModalities: ['AUDIO', 'TEXT']  // ‚Üê ROMPE TODO
```

**Resultado si cambias:** La IA se conecta pero nunca responde (ni audio ni texto).

---

### 2. **VAD / automaticActivityDetection**
```javascript
// ‚ùå INTENTADO Y RECHAZADO POR GEMINI:
realtimeInputConfig: {
    automaticActivityDetection: {
        enabled: true  // ‚Üê API lo rechaza con error 1007
    }
}
```

**Resultado:** WebSocket cierra con error "Unknown name 'enabled'".

**Nota:** VAD parece estar HABILITADO POR DEFECTO sin necesidad de configuraci√≥n.

---

### 3. **Transcripci√≥n de Audio**

#### Estado Actual del Problema:
- `outputAudioTranscription: {}`  ‚Üí Transcribe lo que la IA dice (NO lo que queremos)
- `inputAudioTranscription: {}`   ‚Üí **NO funciona** (deber√≠a transcribir al usuario pero no lo hace)

**Intentos realizados:**
- ‚úÖ `outputAudioTranscription` funcionaba (pero transcrib√≠a a la IA)
- ‚ùå `inputAudioTranscription` NO transcribe nada

**Pendiente:** Investigar por qu√© `inputAudioTranscription` no funciona.

---

## ‚úÖ Lo Que S√ç Funciona Actualmente

### Configuraci√≥n Base que Funciona:
```javascript
const setupMessage = {
    setup: {
        model: `models/${this.config.model}`,
        generationConfig: {
            responseModalities: ['AUDIO'],  // NO CAMBIAR
            speechConfig: {
                voiceConfig: {
                    prebuiltVoiceConfig: {
                        voiceName: 'Kore',
                    },
                },
            },
        },
        systemInstruction: {
            parts: [{
                text: 'SOLO responde cuando el usuario te hable...'
            }],
        },
        // PROBLEMA: inputAudioTranscription no funciona
        // outputAudioTranscription s√≠ funcionaba pero transcribe a la IA
    },
};
```

### Funcionalidades que Funcionan:
1. ‚úÖ **Conexi√≥n WebSocket** - Cliente ‚Üî Servidor ‚Üî Gemini
2. ‚úÖ **Captura de audio** - El micr√≥fono captura voz del usuario
3. ‚úÖ **Reproducci√≥n de audio** - La IA responde con voz
4. ‚úÖ **Guardado de mensajes** - Se guardan al completar turno
5. ‚úÖ **Filtro de pensamientos** - Los "thinking" en ingl√©s se filtran
6. ‚úÖ **Indicador de voz** - "üé§ [Respuesta de voz]" se guarda
7. ‚úÖ **Con aud√≠fonos** - NO hay feedback de audio

---

## üî¥ Problemas Persistentes

### 1. **Transcripci√≥n del Usuario NO Funciona**
**S√≠ntoma:** Se env√≠a audio, la IA responde, pero NO se transcribe lo que el usuario dice.

**Logs:**
```
[VoiceSession] Accumulated user text length: 0
[VoiceSession] No user transcription to save
```

**Causa:** `inputAudioTranscription: {}` no est√° funcionando (raz√≥n desconocida).

### 2. **IA Se Inicia Sola**
**S√≠ntoma:** Al abrir el modal, la IA empieza a hablar sin que el usuario diga nada.

**Posible causa:** System instruction o falta de configuraci√≥n de inicio de turno.

### 3. **Modal No Se Cierra**
**S√≠ntoma:** Al dar click en el bot√≥n X, el modal no se cierra.

**C√≥digo actual:** `handleClose` ‚Üí `disconnect()` ‚Üí `onClose()` (se ve correcto).

**Posible causa:** Componente padre no actualiza estado `isOpen`.

### 4. **Mensajes No Aparecen en Chat**
**S√≠ntoma:** Los mensajes se guardan en la base de datos pero NO aparecen en la UI.

**Causa:** El `queryClient.invalidateQueries` no se est√° disparando correctamente.

---

## üìù Configuraciones que Romp√≠

### Lo Que Funcionaba ANTES y Romp√≠:

1. **outputAudioTranscription funcionaba** (transcrib√≠a la IA, pero al menos funcionaba)
   - Lo cambi√© a `inputAudioTranscription`
   - Ahora NO transcribe NADA

2. **System instruction menos restrictivo**
   - Antes: "Identifica riesgos... analiza..."
   - Ahora: "SOLO responde cuando el usuario te hable"
   - Efecto: IA sigue hablando sola igualmente

---

## üéØ Pr√≥ximos Pasos Sugeridos

### Opci√≥n 1: REVERTIR a Configuraci√≥n Anterior
Volver a `outputAudioTranscription` para que al menos transcriba algo (aunque sea la IA).

### Opci√≥n 2: Investigar Documentaci√≥n Oficial
Buscar EJEMPLOS COMPLETOS de configuraci√≥n de Gemini Live API con transcripci√≥n de usuario.

### Opci√≥n 3: Usar el C√≥digo del Repositorio de Referencia
Copiar la configuraci√≥n EXACTA del repositorio `google-gemini/live-api-web-console`.

---

## üö´ Reglas de Oro

1. **NO cambiar `responseModalities`** sin confirmar que funciona
2. **NO agregar configuraciones** sin verificar en documentaci√≥n oficial
3. **DOCUMENTAR cada cambio** antes de hacerlo
4. **PROBAR cada cambio** individualmente antes de hacer otro
5. **REVERTIR inmediatamente** si algo se rompe

---

## üìä Estado Actual (2025-11-24 18:37)

**Lo que funciona:**
- Conexi√≥n WebSocket ‚úÖ
- Audio del usuario se captura ‚úÖ
- IA responde con voz ‚úÖ
- Con aud√≠fonos, no hay feedback ‚úÖ
- Filtro de pensamientos funciona ‚úÖ

**Lo que NO funciona:**
- Transcripci√≥n del usuario ‚ùå
- IA habla sola ‚ùå
- Modal no cierra ‚ùå
- Mensajes no aparecen en UI ‚ùå
- Conversaci√≥n no se muestra como texto ‚ùå

**Configuraci√≥n actual:**
- `responseModalities: ['AUDIO']`
- `inputAudioTranscription: {}` (NO funciona)
- System instruction: "SOLO responde cuando..."
